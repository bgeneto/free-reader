services:
  # Main Next.js application
  app:
    build:
      context: .
      dockerfile: Dockerfile
      args:
        NEXT_PUBLIC_URL: ${NEXT_PUBLIC_URL:-https://smry.ai}
        NEXT_PUBLIC_CLERK_PUBLISHABLE_KEY: ${NEXT_PUBLIC_CLERK_PUBLISHABLE_KEY}
        NEXT_PUBLIC_LOGODEV_TOKEN: ${NEXT_PUBLIC_LOGODEV_TOKEN}
    container_name: smry-app
    restart: unless-stopped
    ports:
      - "3000:3000"
    environment:
      # Node environment
      NODE_ENV: production
      LOG_LEVEL: info

      # Core API Keys (Required)
      CLERK_SECRET_KEY: ${CLERK_SECRET_KEY}
      NEXT_PUBLIC_CLERK_PUBLISHABLE_KEY: ${NEXT_PUBLIC_CLERK_PUBLISHABLE_KEY}

      # Diffbot for article extraction (Direct & Wayback sources)
      DIFFBOT_API_KEY: ${DIFFBOT_API_KEY}

      # Redis - Upstash managed service
      UPSTASH_REDIS_REST_URL: ${UPSTASH_REDIS_REST_URL}
      UPSTASH_REDIS_REST_TOKEN: ${UPSTASH_REDIS_REST_TOKEN}

      # AI Model Configuration
      OPENAI_BASE_URL: ${OPENAI_BASE_URL:-https://openrouter.ai/api/v1}
      OPENAI_API_KEY: ${OPENAI_API_KEY}
      SUMMARIZATION_MODEL: ${SUMMARIZATION_MODEL:-openai/gpt-oss-20b:free}

      # Logo Retrieval - LogoDev
      NEXT_PUBLIC_LOGODEV_TOKEN: ${NEXT_PUBLIC_LOGODEV_TOKEN}

      # Application URLs
      NEXT_PUBLIC_URL: ${NEXT_PUBLIC_URL:-https://smry.ai}

    # Health check to ensure app is running
    healthcheck:
      test: [ "CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:3000/" ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

    # Resource limits for production
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 2G
        reservations:
          cpus: '1'
          memory: 1G

    # Logging configuration
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

    networks:
      - smry-network

networks:
  smry-network:
    driver: bridge
